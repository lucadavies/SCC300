\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage[font={small,it}]{caption}
\usepackage{graphicx}
\graphicspath{{../}}
\title{\textbf{Using Natural Language Processing to Analyse the Shape of Stories}}
\author{
Luca Davies \\ BSc. (Hons.) Computer Science}
\date{March 2020}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{float}

\begin{document}
\maketitle
\newpage
\section*{TO DO LIST}
    \begin{itemize}
        \item Plus-minus symbol HOW???
        \item Fill out Introduction more
        \item Fill out background (with references)
        \item Anymore to add to Design/Dev section?
        \item Redo Cinderella hand analysis + write up anything interesting
        \item Tidy Reader Reflection
        \item More on Early Modern vs Modern English
            \begin{itemize}
                \item Reference Jonathan Culpeper
            \end{itemize}
        \item Comedy vs Tragedies
        \item Conclusion
            \begin{itemize}
                \item Summary
                \item Relfetion
            \end{itemize}
        \item Project Gutenberg INCONSISTENT HTML FORMAT
    \end{itemize}

\section*{Declaration}
    I certify that the material contained in this dissertation is my own work and does not contain unreferenced or unacknowledged material. I also warrant that the above statement applies to the implementation of the project and all associated documentation. Regarding the electronically submitted work, I consent to this being stored electronically and copied for assessment purposes, including the School’s use of plagiarism detection systems in order to check the integrity of assessed work. \\
    I agree to my dissertation being placed in the public domain, with my name explicitly included as the author of the work. \\
    
    \noindent
    Name: \\
    Date:
\newpage
\section*{Abstract}
    This report examines the application of Natural Language Processing and Sentiment Analysis to fictional texts in an attempt to summarise narrative arcs as a curve on axes of time against positive/negative sentiment. VADER is used to process text for sentiment analysis and further experimentation is carried out to analyse how suitable VADER may be for this task. Corpora was mainly sourced from Project Gutenberg. A tool was developed to carry out a range of experiments on sentiment analysis that employed VADER as it's sentiment analysis engine. Experimentation was carried out in the context of sentiment analysis around the following topics: the coarseness of sentiment analysis; the accurarcy of VADER at sentence level via hand-tagging; sentiment analysis vs. analysis by human readers; early-modern English vs. modern English; Shakespearean comedies vs. tragedies. It was discovered that a more powerful and versatile sentiment analysis engine would likely be needed to produce more readable curves and that a more flexible tool would prove useful for processing different text styles, such as scripts.
\newpage
\tableofcontents
\newpage
\section{Introduction}
    \subsection{Overview}
        Writer Kurt Vonnegut suggested at various points in his career that all stories may be categorised into a relatively small number of basic archetypes based upon the emotional ups and downs experienced within the narrative. He gave each of these novel names such as Man-In-Hole and Boy-Meets-Girl as a simple reference for each. \cite{vonnegutLecture}

        Literature is one of the defining features of the human race. No other creature on Earth can writes, let alone writes about itself. Humanity takes this a step further again, making up fictitious stories, some rooted in reality, some with no basis at all in which we dream and imagine worlds and situations that may never be possible to achieve. Through written word we express emotion. All emotions, happiness, sadness, anger and fear; love, hate, awe and grief – everything humans can feel, we write about. We create characters to express and receive these emotions, they act as vehicles to transfer their feelings to a reader. With all this freedom to write and create without bound, are we actually as free as we perceive?

        Vonnegut suggests that all stories are members of one of a very small number of categories of story that define roughly how the emotional progression of that story pans out. Do writers naturally and unknowingly write literature that falls into these types or is each story as unique as the next, taking its readers along its own path as they go?

        This concept and these questions drew me toward this project proposal. Not only is it a fascinating endeavour to map the emotions of a novel, but as an exploration of the freedom of writers to convey emotions and of how humans often generate categories and groups without even trying.

        With the high-level view clarified, it's important to note the tools within natural language processing that are relevant, namely that in this study, sentiment analysis takes the spotlight. Emotional analysis is a more in-depth field that shifts focus toward the psychological analysis (\cite{sentimentVsEmotionAnalysis}) and employs machine learning and artificial intelligence to further predict and understand the emotions presented in text.
    \subsection{Motivation}
        At it's core, this study is novel. It is interest driven - to attempt to show that stories can be categorised in a very simple and easy manner based upon the emotional arcs they lead readers across is an interesting new way to sort fiction. There may not be any exlicit \textit{need} to categorise literature in this way, however it has the potential to lead to further studies that examine just how it is that humans create literature and nay patterns we follow.
    \subsection{Aims \& Objectives}
        The aims of this report are as such:
        \begin{itemize}
            \item Design and develop an application to process a range of corpora to produce a graphing of the emotional arc during its literary course (as produced using SA)
            \item Analyse a range of corpora for compliance with Kurt Vonnegut’s theories and story shapes
            \item Otherwise attempt to identify potential trends in the texts processed, such as obvious geometric differences between literature generally considered happy/sad
            \item Present graphs of texts to readers who are familiar with the text to assess if their perceptions of the text align with the SA graphs
            \item Assess VADER's ability to process text outside its design remit (e.g. early-modern English)
        \end{itemize}
    \subsection{Report Structure}
        The reminader of this report will disucss relevant background and context, the design and implementation of the Sentiplot tool, followed by a detailing of the experimentation carried out. The report will then be concluded by an analysis of the results acquired from this experimentation.
\newpage
\section{Background}
\label{sec:background)}
    \subsection{Overview}
        This chapter will examine and summarise existing literature and studies in this area and topic. That is, natural language processing and sentiment analysis as a tool for extracting statistical data that describe emotions in (mainly) fictional works of literature.

        The processes involved for finding useful information included searching for online articles and pre-existing projects while searching libraries to use in the implementation, Google Scholar, Lancaster University Library OneSearch and Kurt Vonnegut’s own lectures on this topic.

        Existing projects will help to prove the developed application is performing up to standard (or not) and can be used as a side-by-side comparison of literature processed for this report and by these projects as well as to examine the processing of literature unavailable for the purposes of this report.
    \subsection{Natural Language Processing \& Sentiment Analysis}
        Natural Language Processing (NLP) is a very broad field concerned with, at a high level, the understanding of human language by computers. It fuses linguistics with computer science to not just parse but to \textit{understand} human language, to understand it in such a way that meaning can be deduced and emotion and sentiment can be extracted, even when not fully clear.

        Via the beginnings of machine translation, NLP has existed as a research field for decades, even before the current name was coined. Breakthrough projects like ELIZA made progress in the field, but it wasn't until the 1980s that statistical methods began to be used. Prior to this, large sets of hand-written rules governed how NLP systems worked, which, although sometimes effective, limited the overall progress to the manual effort put into the models and rules. In modern NLP toolkits, models are still prevalent, but instead of them being assembled by hand, they are often formed using machine learning techniques based upon employing training data, test data and then real language data.

        Sentiment Analysis (SA) is a subfield of NLP that focuses on extracting and subsequently quantifying opinion and sentiment around a topic simply by analysing text. SA is a particularly new field, and has so far mainly be used on corpora that is factual and descriptive: product/movie reviews and social media to gauge general public opinion.
    \subsection{Kurt Vonnegut on ``The Shape of Stories''}
        Vonnegut described a number of potential story types as displayed below in figure something. He suggested that all stories fit into a very small number of categories, and moreover, that stories from different cultures around the world may generally trend toward different story types compared to elsewhere. In his lecture on the topic Vonnegut draws out the curves of some well known novels and stories to demonstrate his meaning. Drawing distinct curves with very defined turning points and changes in direction that match up with points in the given literature.
        \begin{figure}
            \centering
            \includegraphics{Misc/VonnegutShapes}
            \caption{Vonnegut's Story Types}
            \label{fig:storyTypes}
        \end{figure}
    \subsection{The Hedonometer Project}
        The Hedonometer project was established to gauge happiness, the world over, starting with Twitter and other social media outlets. The project’s scope has since widened to process corpora direct from books, film scripts, news outlets and other foreign language literature.
\newpage
\section{Sentiplot Tool}
\label{sec:sentiplot}
This section will detail the design and implementation of the tool used to carry out this study, \textit{Sentiplot}. 
    \subsection{Languages \& Libraries}
    This section briefly discusses the choice of programming language and NLP/SA tools used in the Sentiplot tool.
        \subsubsection{Top-level Language}
        \label{subsec:language}
        When selecting which language would be most appropriate to use for this project, my major considerations were my prior knowledge of potential languages and their ease of creation of a pleasant user interface. Availability of NLP tools in each language was also to be considered, but as the end implementation shows, this was not imperative due to cross-platform and cross-language capabilities of the chosen combination of languages and tools.

        A listing of considered languages follows:

        \begin{itemize}
            \item Java
            \begin{itemize}
                \item Strong language knowledge and familiarity
                \item JavaFX and Swing available for interfaces
                \item Native language of Stanford CoreNLP
            \end{itemize}
            \item Python
            \begin{itemize}
                \item Very limited language knowledge
                \item No knowledge of interface building
                \item Native language of industry standard NLTK
            \end{itemize}
            \item C\# (with .NET)
            \begin{itemize}
                \item Strongest language knowledge and familiarity
                \item Extreme ease in creating interfaces via Windows Form using Visual Studio
                \item Cross-platform variants of CoreNLP and VADER available via simple packages
            \end{itemize}
        \end{itemize}
        Taking all these points into consideration C\# was selected, due to its pros specific to myself and the availability of non-native libraries via APIs. This permitted me to use the full Microsoft Visual Studio suite for development, including the Windows Forms designer.
        \subsubsection{Natural Language Processing Tools}
        Various tools across a wide array of languages are freely available to provide standard NLP functions and advanced processing capabilities.

        Initially a full CoreNLP pipeline was employed to process corpora but this proved to be extremely slow, loading around 2 gigabytes of models very slowly into memory before even processing anything. The pipeline was modified to tokenise and sentence-split the input only, and the actual sentiment analysis was performed by VADER.

        Both the CoreNLP and VADER libraries are non-native to C\# but have easy to use APIs for direct manipulation of their types and methods outside of their native environments. CoreNLP has an in-house developed API for C\# and VADER has a third-party API called \textit{VADERSharp}.
    \subsection{Design \& Development}
    \label{subsec:dnd}
        Sentiplot was developed over the course of two academic terms between early October 2019 and late January 2020. The first few weeks involved mainly research into what language was to be used and what NLP/SA tools or toolkits would provide the best mix of suitability-to-task and ease of use. The initial framework and basic features were developed using a waterfall type methodology before later, more experimental features were developed in a more ad hoc manner using an agile development process \textit{after} the main program with built.
        
        The base applicaition was projected to take 4-5 weeks to develop from scratch and the smaller experimental features added after to each take aroudn a week. In reality, this first stage of developement occupied the majority of the time from the start of November through till mid December. Then each of the experimental features pushed on frm there, rolling into the next term, rather than all being finished before the Christmas holidays. Thankfully this did not cause major issues as there was an excess of time set aside for write up in the second term. Final bits of development including housekeeping and codestyling wrapped up approaching week two of February 2020, still allowing time for this report write-up.

        As in discussed in section \ref{subsec:language}, C\# was the language used and Windows Forms was the user interface framework chosen. A full Visual Studio (Community) development suite was used to design, build and test the application which allowed for relatively switft and easy development due to the neat integration bewteen the technologies. Had a different, less familair language/framework been adopted, further schedule overruns may have occured. StanfordCoreNLP was at one point the NLP tool of choice, however, dificulty and delay in marrying its Java libraries to C\# and setting up its processing pipeline are in large part what encouraged the eventual swap to VADER in early December.
        
        As the language and framworks use lend themselves to it, the application is built with an object-oriented pattern in mind, however this doesn't come to light much as the application is somewhat self-contained - no other classes or applications need interface with it, Sentiplot only uses simple API calls to any external libraries.

        The overall internal structure of Sentiplot is not massively complicated. It is detailed in section \ref{subsec:implementation}.
    \subsection{Implementation}
    \label{subsec:implementation}
        \subsubsection{Structure}
            The application is written in C\# .NET interfacing with both Java and Python libraries via APIs as detailed in sections \ref{subsec:language} and \ref{subsec:dnd}. Windows Forms was chosen for the interface as a quick and easy to build platform, stable on Windows with seamless integration into C\# and the .NET framework.

            The application is composed of two forms, each with their designer code. The first allows the user to select a file to load text from and set processing granularity. The second presents the results of the analysis in multiple ways and provides facility to save these results as images of the output graphs.
        \subsubsection{Sentiplot Form (Main Form)}
            This is the main form for the application. It is loaded on start-up and contains all needed information or otherwise calls other classes to complete its task.

            Its key functions include:
            \begin{itemize}
                \item Initialising the CoreNLP pipeline ot tokenise the input text
                \item Generating an OpenFileDialog object to allow the user to select a \textit{.txt} or \textit{.html} file
                \item Parsing the content of the input file to prepare it for processing using regular expressions and simple character-based splitting
            \end{itemize}
        \subsubsection{ResultsViewer}
            This form displays the results of VADER's processing of the input text. It displays a graph of the entire text from start to finish, a full list of all tokenised sentences and their associated sentiment scores (in tabular form) and individual graphs for each chapter in the text (HTML file only).

            \begin{itemize}
                \item Handling the output data and feeding it into the main chart and table
                \item Allow hiding/showing of each different type of sentiment score for the main graph
                \item Dynamically producing more tabs on the form to show each successive group of five chapters
            \end{itemize}
    \subsection{User Interface}
        The implemented interface did not need to be excessively complex or particularly appealing as it mainly served to function as a harness to conduct the study, with more importance placed on the code-behind and results.

        To provide quick results and ease of programming, I used the Windows Forms suite to produce a visually simple but functional interface. It has two screens: a screen to load the desired text to be processed and to set the granularity of the analysis, and a screen to present the processed results. The following sections provide an overview of these screens.
    \subsubsection{Text Selection \& Options}
    Figure \ref{fig:sentiplot} shows the main presented screen, after having loaded an HTML file (Hamlet in this case) which has been parsed to produce plaintext, having stripped out all the unneeded HTML tags.
        \begin{figure}[H]
            \includegraphics[width=1\textwidth]{Misc/sentiplot}
            \caption{Main Sentiplot window}
            \label{fig:sentiplot}
        \end{figure}
    \subsubsection{Results Display}
        Figure \ref{fig:resultsviewer} shows the results screen for Hamlet, initially showing the graph of the entire text. The maximum and minimum points are labeled with the start of the related sentence. Hovering the mouse over these labels shows the entire sentence or sentences that produced that datapoint.

        For every sentence analysed VADER returns four sentiment scores: positive, neutral and negative (each holding a -1 to 1 score regarding match to that sentiment), and compound which acts as a single representation for the sentiment in the sentence parsed. Each of these scores have their own graph which may have their visibility toggled on and off with the check boxes in the bottom left. (Default is compound alone, as it proved the most indictive of sentiment, as advised by VADER documentation.) This graph can be saved to a JPG by clicking the save button.
        \begin{figure}[H]
            \includegraphics[width=1\textwidth]{Misc/resultsviewer}
            \caption{ResultsViewer window}
            \label{fig:resultsviewer}
        \end{figure}
        Figure \ref{fig:resultstable} shows the Table tab of the results screen. This simply lists each individual sentence token in the input with VADER’s output value for the four scores mentioned previously. The table’s default ordering in by sentence index, or the chronological order in the text, but the it may be order by any of the fields shown.
        \begin{figure}[H]
            \includegraphics[width=1\textwidth]{Misc/resultstable}
            \caption{ResultsViewer window showing table}
            \label{fig:resultstable}
        \end{figure}
        Figure \ref{fig:resultschapters} shows one of the chapter tabs from the results screen. Each of graphs the compound sentiment score of up to 5 chapters from the processed text. Again, maxima and minima are labeled with their relevant sentence(s), expandable by hovering the mouse over the label.
        \begin{figure}[H]
            \includegraphics[width=1\textwidth]{Misc/resultschapters}
            \caption{ResultsViewer window showing chapter graphs}
            \label{fig:resultschapters}
        \end{figure}
\newpage
\section{Experimentation}
The following section covers the various experimentation and analysis carried out using Sentiplot as a tool for Sentiment Analysis and graphing accordingly.
    \subsection{Analysis Block Size}
        Sentiplot incorporates one primary setting for its analysis of texts: the granularity slider. This allows the user to select varying degrees of granularity for the produced graphs (as a percentage of the text being analysed). This allowed analysis of texts at a number detail levels to find which produced the most obvious curves to conform with Vonnegut's story curves. This may have introduced a small amount of positive-results bias, accepting those granularities that appear most curve-like for a given text instead of what may have actually reflected the curve of the text.

        The options provided and their effectiveness are shown in figure \ref{fig:granChart}.
        
        \begin{figure}[hbt]
            \begin{center}
                \begin{tabular}{ |c|c|c| } 
                \hline
                \textbf{Too Fine} & \textbf{Acceptable} & \textbf{Too Coarse} \\ 
                \hline
                1 Sentence & 0.2\% & 5\% \\ 
                0.1\% & 0.5\% & 10\% \\
                & 1\% & 25\% \\
                & 2\% & 50\% \\
                &  & 100\% \\        
                \hline
                \end{tabular}
            \end{center}
            \centering
            \caption{Various granularities are available for processing text, this table shows those that proved the most effective and those that did not.}
            \label{fig:granChart}
        \end{figure}
        This set of experiments varied the analysis blocksize for a given text and compared the output graphs for the entire text with a view to identifying a specific curve for the text. The comparison is qualitative, employing only human visual reference as opposed to any mathematical function. The purpose of this part of the study was as a forerunner to further analysis and experimentation to find the best setting or the best range of settings for either specific or generically for all texts to produce a coherent sentiment curve.
        \begin{figure}
            \includegraphics[width=1\textwidth]{Figures/Blocksize/Cinderella/cinderellaGran}
            \centering
            \caption{Each graph shows the result of decreasing the granularity of analysis and show how there appears to be a sweet spot. In this case, four of the highest options summed only a single sentence due to short length of the text. Only one of these has been included.}
            \label{fig:cinderellaGran}
        \end{figure}
        Figure \ref{fig:cinderellaGran} show the differing graphs that may be produced by changing the granularity.

        VADER is designed for parsing short lengths of text (less than 140 characters, as per a Tweet), so in order to produce more coarse graphs than single-sentence, VADER is still fed text on a per-sentence basis with the results summed up to \textit{N} sentences where \textit{N} is the corresponding number of sentences for a given granularity setting for a given text. The relevant data point is then plotted \textit{N} sentences beyond the previous (i.e. at the end of the analysed block).

        By default, every sentence of the text is plotted as its own point. This gives highly detailed graph but it very difficult to discern any sort of shape. Sentence to sentence, sentiment can vary wildly from the most negative in one to the most positive in the next (context and corpus dependent). Due to this, the resultant graph is highly spiked and difficult to garner information from.

        By contrast, using the more coarse options of 25\% and upward produce graphs that do show a clear line, the hope being the larger regions that have an average higher/lower sentiment score can then be picked out. However, at this level of coarseness, the data is compressed so much so that most of the detail is lost, smoothing the curve beyond useful limits for purposes of analysis

        Through trial-and-error experimentation, the ideal setting was found to lie between 0.2\% and 2\%, erring toward the 2\% for most texts. Although the choice to use percentages for the granularity setting was made to better cater to both long and short texts, those that are particularly long (>5000 sentences) and those that are particularly short (<200 sentences) may require different settings to best show the data and thus the curve. This is due to the fact that a longer novel does not necessarily have longer chapters and/or longer sections that could be identified as having a partiular bias in sentiment.
        
        With all this being said, it's possible, that a different tool may have been better suited overall to this task than VADER is, due, at least in part, to it's native design choice to parse text the length of Tweets, not entire corpora. Sentiplot could be redesigned to pass VADER each block as a whole instead of summing the individual sentence values instead, although it is to be assumed that this would yield less accurate results as this is not how VADER was intended to be used.
    \subsection{Hand Analysis Vs. VADER}
        This test was performed by selecting a 100 random sentences from two texts (Macbeth and Cinderella), analysing them each individually by hand and estimating a combined positive/negative sentiment score in the same range as that produced by VADER. I attempted to avoid trying to emulate the way VADER would process the text, instead scoring each sentence as I would as a reader of the text: "Would I feel positively and negatively after reading this sentence?" or, similar - a human approach.
        
        The motivation behind this was to understand if VADER's output results were trustful, totally incorrect, or somewhere in the middle. It's easy to blindly follow what a program says but NLP and Sentiment Analysis is still very much a field that cannot yet directly emulate the processes of the human brain.
    
        \begin{figure}[hbt]
            \includegraphics[width=1\textwidth]{Figures/HandAnalysis/Macbeth}
            \centering
            \caption{An excerpt from the table of human-analysed sentiment scores along side VADER's scores with the difference (highlighted green for a match, red otherwise) shown. The original sentences from Macbeth are shown for reference.}
            \label{fig:handMacbeth}
        \end{figure}
        
        The results obtained, although they are based on one person's own judgement (and hence are not necessarily reliable), were disappointing to say the least. To determine similarity, a threshold difference of +/-0.25 was chosen to mark the boundary between results that correlated with each other, and results did not. From this, of the 100 sentences taken from Cinderella, only 27\% matched. In the case of Macbeth, 50\% matched, but it is possible to theorise that majority of the increase is likely due to the fact of Macbeth being a script - namely, there were many sentences that were just a name, or just a stage direction alone and thus was very easy to be rated neutral (or, zero) by both a human and VADER. However, in the 100 sentences, 29 names, stage directions or similar were present, of which 10 matched (mainly at or near zero), decreasing the effective percentage of matched sentences to somewhere in the range 21\%-40\%. There were some cases where a plain name resulted in an extreme score (see rows 4 and 9 in figure \ref{fig:handMacbeth}). Some of the scores assigned by VADER also seem to make little to no sesne whatsoever, for example, row 7 in figure \ref{fig:handMacbeth}: the full sentence directly includes (without negation), the words ``bloody'', ``avaricious'', ``false'', ``deceitful'', ``malicious'', and ``sin'', and yet VADER scores the sentence all but neutral, while most human readers would likely rate this one of the most negative in the data set.

        Though not in the previous example, it is possible that some of these erroneous results may stem from the fact that the way VADER is being utilised in Sentiplot means that it has no context for any given sentence, they are all processed stand-alone and so VADER cannot build up any running themes or patterns to aid in analysis.

        To conclude, this experiment raised potential issue with the usage of VADER, suggesting an alteration in Sentiplot's implementation but also questioned the overall effectiveness of VADER as a sentiment analysis tool given some rather unusual results upon close inspection. The next section partially opens up this discussion to a wider audience, allowing comment on the final results produced by VADER and some comments on its processes.
    \subsection{Reader Analysis \& Reflection}
    \label{subsec:reader}
        This section covers the analysis of a range of Shakespeare plays by human readers (mostly identified to be Theatre and/or Literature students) and their personal comparison of the the Sentiplot output with their own expectations of what a graph of a given play should be. The goal here was to bring a human element to the reviewing of Sentiplot and VADER. A brief background of the study, its goals, and task was given to each person who answered any of the questions provided. Some asked further questions and subsequently commented on the techniques used for analysis and graph production.
        \subsubsection{Reader Analysis}
            Readers were first asked if they felt they knew each play well enough to attempt to plot a rough arc for each on a set of axes, with a focus on any major emotional events they could identify. Some participants opted to answer questions on only a subset of the plays, as they may not have read or otherwise cannot remember the other plays. In total, 22 result sets were gathered. This allows qualitative analysis to be carried out around how effectively VADER performed from a human perspective and to attempt to gather further comment from participants on the effectiveness of Sentiplot.

            Each participant was given a blank set of axes (with the same scale as was used for VADER's results). They were asked to draw what they thought a curve of each play would look like, based upon any and all major events they can recall. They were then asked to label and/or explain any notable peaks and troughs in their curves. A small selection of the curves drawn are shown in figure \ref{fig:readerVsVader}, paired with the corresponding output form VADER.
            \begin{figure}[ht]
                \includegraphics[width=1\textwidth]{Figures/Survey/readerVsVader}
                \centering
                \caption{Readers (top of each pair) in general drew curves bearing little to no similarity to those produced by VADER (bottom in each pair)}
                \label{fig:readerVsVader}
            \end{figure}
            In general, all the curves drawn by participants were wildl different to the VADER output for the same texts. All VADER's curves stayed mostly in the range of +/-0.25 on the Sentiment axis, whereas most participants drew curves using nearly the full extent of the y-axis. It was to be expected that participants would use the full axis, but it was not expected before setting out on this experiment that VADER's graphs would be quite so restricted. This is not to say that VADER doesn't register any sentences as reaching the more extreme values: when examining the per-sentence scores in the table view, it does, but these values get flattened when they are grouped together. On closer inspection, taking Macbeth as an example, approximately 30\% of the sentences were outside the +/-0.25 range, however  just over 60\% of those \textit{within} that range were zeros: registered by VADER as completely neutral sentences. When taking averages, these high volumes of zero-scored sentences reduced the impact on the output graph of higher scores greatly.

            Even with this failure, attempting to look at relative differences along the two curve sets (those drawn, and those produced by VADER) still doesn't yield much similarity. The only immediately obvious correlation is, again, in Macbeth where both VADER and a participant show a sharp dip at around the halfway mark (labeled on the drawn curve as "murder"). This is nearly the only obvious match.
            
            Kurt Vonnegut suggested in his lecture that Hamlet ought to have a somewhat flat curve. Sentiplot supports this at least visually, however, some of the drawn graphs show a very clear descent, logically coupling Hamlet's madness with negative sentiment. Sentiplot does in fact also show some extreme peaks and troughs, however these are momentary in the overall context of the script, and thus are averaged out and do not appear in the final output. Depending on the scope at which you examine, but Sentiplot has elements of agreement with both Vonnegut's flat prediction \textit{and} participant's more curved graphs.
			\subsubsection{Reader Reflection}
                Participants were later asked to comment on the similarity (or dissimilarity) between their own graphs and those from VADER. There was a general consensus that VADER's graphs lacked the ability to show various details and intricacies of the literature or were otherwsie just plain wrong. 
                One particpant noted the failure of the system pickup on tonal dissonances within a Midsummer Night's Dream - this is assumedly a reference to the multiple plot lines within the play and their sometimes conflicting emotional tones. If VADER had a greater capability to distinguish plot lines and characters within a text from one another, it's highly likely that each plot within a text would have its own curve.
                
                It was also said that the Sentiplot graphs failed to pick up on even the extremities of character emotions (namely in Romeo and Juleit) and also in the overall tone of a play (Hamlet, showing as being relatively neutral when expected to be generally negative).

                Another particpant mentioned that they felt undertones in the text were totally lost in the graphs (though this is perhaps to be expected) and that they failed to differentiation netween specific known periods of happy/sad narritive segements. One specific example of this is seen at the end of Romeo and Juliet - a decidedly negative section of literature, at least at surface level. Of the two responses for Romeo and Juliet received, both finish the play below zero, with one plummeting the sentiment score down to maximum negative. By contrast, VADER's graph actually \textit{rises} at the end, the second highest point in the entire graph. This is a major error, of course, but after seeing the results, the text processed was examined closer and it was found that Sentiplot had failed to strip out the sizable Project Gutenberg pre- and postamble in the processed HTML file. It was the postamble (making up the final 5\% of the text) that gave rise to this upward spike where there was otherwise a negative trend that met readers expectations. Unfortunately it was found that this was not an isolated issue and is covered in more detail in section \ref{sec:gutenbergFormat}.
                
                A few participants noted that some of VADER's graph appeared to have little to no correlation with the text at all, with some attributing this to a computer program's lack of the ability to experience or empathise with literary art. It was also suggested that a theatrical script is likely to be a less than ideal format for attempting to produce a curve in this way, with one participant pointing out that scripts do not contain significant amounts of description - they only contain dialogue, with a small (albeit, varying) amount of description present in the stage directions; novels on the other hand innately contain description as it is the primary information is conveyed to the reader.
    \subsection{Early Modern Vs. Modern English}
        In this experiment, ``varded'' variants of six Shakespearean plays were processed by Sentiplot. The varded texts are modern English variants of Shakespeare's texts, the goal here being to compare just how much of an impact the difference in language (early-modern English vs. modern English) has on the ability of VADER to analyse sentiment.

        VADER is not trained to work on the likes of formal literature. In fact, it is trained to work on highly modern and informal text, to such an extent that it can understand and analyse Internet slang and emoji. Due to this fact, this experiment was carried out to test if VADER was able perform equally or at all as well on a different form of English, that being the Early Modern English found in the Shakespeare plays processed for sections \ref{subsec:reader} and \ref{subsec:comVsTrag}. The assumption is that VADER will perform better on modernised texts, as that is what its models have been trained to process.
        
        The original Project Gutenberg texts of the plays gave graphs that did not hold much variation - processing the moderised text overall gave similar graphs at first glance, similar but with exaggerated peaks and troughs with the overall form is still held. However, finer inspection will show that in fact, there's a number of new features visible in most plays that were not present in the original text. For example: in the latter 40\% of the original text of \textit{The Tempest}, the graph has less and less varitation, staying practically in the range of zero to 0.1 - in direct opposition, the varded text has a number of large peaks and troughs, with a maximum magnitude score of approximately positive 0.3. Similarly, in \textit{A Midsummer Nights Dream}, just after the halfway mark, there appears to be a fairly distinctive negative period for a while, a feature that isn't shown at all on the original text (in fact, it appears to go become more \textit{positive}).

        These new additions seen in most graphs demonstrate VADER's limited ability to process non-modern English text, causing it produce values erring much more toward neutral zero-values than it should. It is still reasonable to attribute the restricted nature of the these original graphs, at least partially, to the nature of the text, them being scripts, not novels, however it can still be seen on that modern English is processed to give more meaningful results as shown in the huge variation (nearly full -1 to 1) of the graph of Cinderella in figure \ref{fig:cinderellaGran}. Upon close inspection of the graphs of the other modernised texts, it can also be seen that some of them are not \textit{just} exaggerated, but also show new features, and in some cases show the opposite to the originals. For example: DO THIS BIT
        \begin{figure}
            \includegraphics[width=1\textwidth]{Figures/EMvsM/EMvsM}
            \centering
            \caption{Original (early modern English) text graphed on the left, along shide hand-modernised text on the right for four plays.}
            \label{fig:emvsm}
        \end{figure}
    \subsection{Shakespeare: Comedies Vs. Tragedies}
    \label{subsec:comVsTrag}
        As mentioned in section \ref{subsec:reader}, Shakespeare plays have been a key source of analysis text. These have generally yielded somewhat restricted graphs. The motivation for these tests came from the thought to force the ability to tell apart different plays by their genre. Namely to comedies \textit{should} show generally more positive curves and similarly, tragedies \textit{should} show more negative curves accordingly. To attempt to display this, three comedies (\textit{Twelfth Night, The Tempest, A Midsummer Night's Dream}) and three tragedies (\textit{Macbeth, Hamlet, Romeo \& Juliet}) were processed to give their repsective graphs. There is some debate on the specific genre of \textit{The Tempest}, it now often being referred to as a ``late romance'', a subsection of Shakespeare's comedies leaning more toward a ``tragicomedy'' in genre. Nonetheless it ought to still produce a difference in curve to that of the three tragedies.
\newpage
\section{Project Gutenberg Formating}
\label{sec:gutenbergFormat}
        THERE IS NO STANDARD D':
\newpage
\section{Conclusion}
	This is a conclusion.
\label{sec:conclusion}
\newpage
\bibliographystyle{plain}
\bibliography{ref}
\end{document}
